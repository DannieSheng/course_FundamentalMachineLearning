\relax 
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the multiple-layer perceptron neural network}}{1}}
\newlabel{flowchart}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Decision boundaries after networks training with the input data}}{2}}
\newlabel{inputDB}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Left: The weight track of the training of the neural network. Right: The resulting error on training data with the trained network.}}{3}}
\newlabel{WTerror}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Generated data and decision boundaries}}{4}}
\newlabel{inputDB_test}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Left: Training data and decision boundaries with $\alpha = 1$. Right: Training data and decision boundaries with $\alpha = 5$.}}{4}}
\newlabel{inputDB_test16nearest}{{5}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Left: 16 data nearest to the origin and decision boundaries. Right: 16 data farthest to the origin and decision boundaries}}{6}}
\newlabel{inputDB_test16nearest}{{6}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Two way of building models theoretically}}{7}}
\newlabel{models}{{7}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Corresponding decision boundaries with samples of this problem.}}{7}}
\newlabel{modelsplot}{{8}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Left: Decision boundary of the network with hand-selected parameters. Right: Eight errors occur with the net work using hand-selected parameters.}}{8}}
\newlabel{modelsplot}{{9}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The sigmoid function with different values of $\alpha $}}{9}}
\newlabel{sigmoid}{{10}{9}}
