\relax 
\citation{b1}
\citation{b2}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Multi-layer Perceptron with 2 Hidden Layers.}}{1}}
\newlabel{ANN}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Methodology}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Artificial neural network}{1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0a}Single processing element}{1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-A}0b}Multilayer Perceptrons}{1}}
\citation{b6}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Single processing element of an artificial neural network.}}{2}}
\newlabel{PE}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Backpropagation}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-B}0a}Training Approaches}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Artificial Neural Network Training Algorithm}}{2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-B}0b}Update with momentum}{2}}
\citation{b4}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {II-B}0c}Regularization with dropout}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Principal component analysis}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Schematic diagram of network dropout. Left: standard network. Right: Dropout network}}{3}}
\newlabel{Dropout}{{3}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Results}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Dimensionality reduction}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Plot of fraction of total variance retained vs. number of eigenvalues}}{3}}
\newlabel{PCA}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}One hidden layer neural network}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Left: learning curve of train set as well as validation set with 100 hidden units. Right: accuracy curve of train set as well as validation set with 100 hidden units.}}{4}}
\newlabel{1hidden100}{{5}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Left: learning curve of train set as well as validation set with 400 hidden units. Right: accuracy curve of train set as well as validation set with 400 hidden units.}}{4}}
\newlabel{1hidden400}{{6}{4}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-B}0a}Performance of the neural network with different step size}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Left: learning curve of train set as well as validation set with 700 hidden units. Right: accuracy curve of train set as well as validation set with 700 hidden units.}}{4}}
\newlabel{1hidden700}{{7}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Left: learning curve of train set as well as validation set with 800 hidden units. Right: accuracy curve of train set as well as validation set with 800 hidden units.}}{4}}
\newlabel{1hidden800}{{8}{4}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-B}0b}Performance of the neural network with different dimension retained}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Table of experiment results}}{5}}
\newlabel{tab: t1}{{I}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Plot of error bar with different number of hidden units}}{5}}
\newlabel{errorBar}{{9}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Learning curves with different step size.}}{5}}
\newlabel{LCSS}{{10}{5}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-B}0c}Performance of the neural network with momentum term}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Plot of error bar with different number of dimensionality retained.}}{5}}
\newlabel{errorBarPCA}{{11}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Weight track without momentum term step size $\eta = 0.05$. Left: output weight. Right: output bias.}}{5}}
\newlabel{WTno}{{12}{5}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-B}0d}Performance of the neural network with dropout}{5}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {III-B}0e}Confusion matrix on the test set}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Table of experiment results with different dimensionality retained by PCA}}{6}}
\newlabel{tab: t2}{{II}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Weight track without momentum term step size $\eta = 0.05$. Left: output weight. Right: output bias.}}{6}}
\newlabel{WTM}{{13}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Comparison of the performance of the same neural network, with or without dropout.}}{6}}
\newlabel{dO}{{14}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Discussion}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Confusion matrix for the final model test no the test data set, where ``class 1" represent for number ``0", and so forth.}}{6}}
\newlabel{confu}{{15}{6}}
\citation{b5}
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusions}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
